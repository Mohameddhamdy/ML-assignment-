In [1]:

import pandas as pd

import numpy as np: from sklearn.preprocessing import OneHotEncoder

from sklearn.compose import ColumnTransformer

from sklearn.ensemble import RandomForest Regressor from sklearn.model_selection import train_test_split

In [2]: data = pd.read_csv("car-sales-extended.csv")
In [5]: np.unique(data["Colour"]) Out[5]: array(['Black', 'Blue',

'Green",

"Red", "White'], dtype=object)

In [6]: np.unique(data["Make"])

Out[6]: array(['BMW', 'Honda', 'Nissan', 'Toyota'], dtype=object)
In [?]:

np.unique(data["Doors"])

Out[?]: array([3, 4, 5], dtype=Int64)

now we must colect all that featers in one list

In [8]: category featur= ["

"Colour", "Doors"]

In [9]:

category_featur

Out[9 ]: ['Make', 'Colour', 'Doors']

now to the transform step

In [10]:

one hot

= OneHotEncoder()

sec step in the transformation transformer Column Transformer("label(one hot", the function one hot, variables(columns that ="passthrough") do not forget the remainder to not drop the columns

In [

11]: transformer ColumnTransformer(((

"one hot", one hot, category featur )]

, remainder =

"passthrough")

In [12]:

transformer

Out[12]: ColumnTransformer (remainder-passthrough",

transformers [('one hot, OneHotEncoder(), I'Make', 'Colour', 'Doors'])])
In [13]; transformer_data = transformer.fit_transform(data)
In [15]: pd.DataFrame(transformer_data)
In [16] dummies pd.get_dumies(data!! "Make", "Colour", "Doors" 11)
In [18]: y = data["Price"]

In [19]: train, test, y train, y tests train test split transformer data, y, test sizes 0.2)

In [20]: Intx test)

Out [20] 200

In Out [21] 300

[21] lan(x_train)

In [22] mode] = RandonForesttegressor()

In [23]: model.fit(x_train,y_train)

Out [23]: RandomForestilegressor()

In [

24]: y predict = model.predict(x_tast)

In 125]: model.score(x_test, test)
